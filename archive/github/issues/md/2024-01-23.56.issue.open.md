# [\#56 Issue](https://github.com/milahu/alchi/issues/56) `open`: schlechte nachrichten. german version of "news of collapse"

#### <img src="https://avatars.githubusercontent.com/u/12958815?v=4" width="50">[milahu](https://github.com/milahu) opened issue at [2024-01-23 09:46](https://github.com/milahu/alchi/issues/56):

wer den weltuntergang NICHT sieht, der liest die falschen nachrichten
(blaue pillen)

welche news lese ich? also, wem glaube ich?

------------------------------------------------------------------------

german version of "news of collapse" \#32 \#55

------------------------------------------------------------------------

zensur, EU, Digital Services Act

2024-01-20

> Das alles soll die Meinungsfreiheit schützen. Doch wessen
> Meinungsfreiheit? Die jener Nutzer, die sich selbst zensieren, bevor
> die Plattformanbieter es aus Angst vor Milliardenbußgeldern tun? Man
> bekommt den Eindruck, **dieses Gesetz soll nur einen schützen: Die
> EU.**

<https://www.anonymousnews.org/international/die-bruesseler-zensur-krake/>

<blockquote>

## Die Brüsseler Zensur-Krake

Der von der EU verabschiedete Digital Service Act wird im Februar in
Deutschland in Kraft treten. Es baut einen bisher für liberale
Demokratien beispiellosen staatlichen Zensurapparat für das Internet.

von [Eine Analyseo](https://twitter.com/ElisaDavid_)

Der Digital Services Act (DSA) soll Europa „fit für das digitale
Zeitalter machen“, so schreibt man es auf der Website der EU. „Ein
einziges Regelwerk für die ganze EU für einen sichereren und offenen
digitalen Raum, in dem europäische Werte im Mittelpunkt stehen“ soll der
Digital Service Act zusammen mit dem Digital Market Act (DMA) bilden.
Unter anderem sollen Internetplattformen „transparent und
rechenschaftspflichtig“ gemacht werden – um die Meinungsfreiheit zu
schützen.

So nützlich die digitalen Dienste auch sein mögen, die wir täglich
nutzen, „um miteinander zu kommunizieren“ oder „Informationen zu finden“
– sie werden auch missbraucht um etwa Desinformationen zu streuen,
erläutert die EU weiter. „Diese Herausforderungen und die Art und Weise
wie Plattformen sie angehen, haben erhebliche Auswirkungen auf die
Grundrechte im Internet.“ Das Ziel des Gesetzes, so wird es immer wieder
betont, ist der Schutz der Grundrechte an vorderster Front.

Das Gesetz wurde im Sommer 2022 in der EU verabschiedet und am 27.
Oktober 2022 im Amtsblatt veröffentlicht. Am 16. November 2022 trat es
in Kraft. Doch erst am 17. Februar 2024 wird es in Deutschland im vollen
Umfang rechtsverbindlich werden. Zusätzlich will der Bundestag vorher
noch ein Gesetz beschließen, um den Digital Service Act zu
konkretisieren.

### Gesetz verpflichtet auch zur Löschung nichtstrafbarer Inhalte

Das Gesetz ist in seiner Materie sehr kompliziert und komplex.
Spezifische Begriffe aus der Informatik werden juristisch definiert,
Abläufe näher geregelt und Verantwortungsbereiche abgewogen. Der Digital
Service Act gilt für sogenannte „Vermittlungsdienste“, denen umfassende
Pflichten auferlegt werden. Der Begriff der Vermittlungsdienste ist
breit gefasst. Artikel 3 (g) DSA zählt darunter neben reinen
Durchleitungsdienste und Caching-Diensten auch Hosting-Provider.

Von besonderer Bedeutung ist dabei ein Unterbegriff der Hosting-Dienste,
nämlich Online-Plattformen wie Twitter, Facebook und Instagram.
Besonders Online-Plattformen und Suchmaschinen mit durchschnittlich
mindestens 45 Millionen aktiven Nutzern in der EU treffen empfindliche
Pflichten. Nach eigenen Angaben zählen dazu Twitter, Google und Meta,
wie die Tagesschau im Februar 2023 berichtete.

Doch während der Gesetzgeber an den einen Stellen sehr komplex definiert
und einordnet, wird er plötzlich an ganz entscheidenen Stellen
schwammig. In Artikel 3 des Gesetzes wird zwar der Begriff
„rechtswidrige Inhalte“ definiert. Doch im Gesetz werden rechtswidrige
Inhalte nicht alleine problematisiert. Immer wieder ist die Rede von
Inhalten, die sich nachteilig auf die Grundrechte aus der EU-Charta, die
gesellschaftliche Debatte, Wahlprozesse oder die öffentliche Sicherheit
auswirken können. Das ist höchst problematisch.

Warum zählen diese Inhalte nicht unter den Begriff der strafbaren
Inhalte? Grund dafür muss zwingend sein, dass sie nicht strafbar sind.
Doch was sind Inhalte, die sich negativ auf Grundrechte, die
Debattenkultur oder Wahlen auswirken können, sich aber im legalen Raum
bewegen? Die Deutungshoheit darüber bleibt bei der EU. Sie kann die
Anbieter der betroffnen Plattformen dazu verpflichten, diese Inhalte zu
überwachen, zu zensieren oder anderweitig zu bekämpfen. Kommen die
betroffenen Unternehmen ihren angeordneten Pflichten nicht nach, so
drohen empfindlich hohe Bußgelder von bis zu sechs Prozent des
weltweiten Jahresumsatzes – das würde auf Zahlungen in Milliardenhöhe
hinauslaufen.

### Die staatliche Drangsalierung zur Selbstüberwachung

Die Verpflichtungen, die der Digital Service Act den großen Anbietern
auferlegt, sind hart. So müssen sie etwa gemäß Artikel 34 jährliche
„Risikobewertungen“ schreiben und an die EU übermitteln. Dabei müssen
sie analysieren, inwieweit rechtswidrige Inhalte – oder wieder die
undefinierbaren Inhalte mit „nachteiligen Auswirkungen“ – auf den
Plattformen oder Suchmaschinen verbreitet werden und dabei systematische
Risiken darstellen. Anbieter sozialer Netzwerke müssen damit
Einschätzungen treffen, zu denen sie weder befähigt noch geeignet sind.
Twitter, Google und Co. müssen ihre Inhalte auf mögliche Gefahren für
die EU untersuchen – Aufgaben, die man instinktiv eher in den
Zuständigkeitsbereich von Behörden wie der Polizei oder den
Geheimdiensten zählen würde.

Auf Grundlage dieser Risikobewertungen sind die Anbieter dann dazu
verpflichtet, Maßnahmen zu treffen, um diese systematischen Risiken aus
dem Weg zu schaffen – „Risikominderung“ nennt sich das. Zu diesen
Maßnahmen zählt ganz zentral die Inhaltsmoderation. Inhalte, die
beispielsweise unter „rechtswidrige Hetze“ fallen, sollen rasch gelöscht
und die verbreitenden Accounts gesperrt werden. Auch die Europäische
Union wird jährlich Berichte schreiben, in der die Bekämpfung der
„systematischen Risiken“ durch Anbieter analysiert werden soll, weiter
will die Kommission Empfehlungen für besonders wirksame Mittel
herausgeben.

Einmal jährlich sollen die Anbieter – auf eigene Kosten – einer
unabhängigen Prüfung unterzogen werden. Darin soll die Umsetzung der
ihnen auferlegten Pflichten kontrolliert werden. Die Plattform- und
Suchmaschinen-Anbieter müssen für diese Überprüfungen „alle relevanten
Daten und Räumlichkeiten gewähren und mündliche oder schriftliche Fragen
beantworten“. Das angemessene Maß an Vertraulichkeit und die Einhaltung
der Geheimhaltungspflicht muss bei diesen Prüfungen nur soweit
eingehalten werden, wie es die Arbeit nicht erschwert. Die Kommission
berechnet den Plattformen außerdem jährliche Aufsichtsgebühren bis zu
0,05 Prozent der weltweiten Jahresnettoeinnahmen.

Die Plattformen müssen staatlichen Behörden zur Kontrolle ausgiebigen
Datenzugang gewähren, wie das Gesetz in Artikel 40 unter dem Punkt
„Datenzugang und Kontrolle“ umfassend festlegt. Außerdem haben die
Anbieter Compliance-Abteilungen einzuführen, deren Aufgaben staatlich
vorgeschrieben sind. Sie haben mit den staatlichen Vertretern
zusammenzuarbeiten und dafür zu sorgen, dass die Pflichten, die der
Digital Service Act den Unternehmen auferlegt, erfüllt werden. Alles
immer mit dem Damoklesschwert der Bußgelder in Milliardenhöhe über dem
Kopf. Im Grunde stehen Twitter, Google und Co. damit unter ständiger
staatlicher Beobachtung und Kontrolle.

### Pandemien und Kriege können verschärfte Eingriffe begründen

Unter Erwägungspunkt 91 des Gesetzes wird als Ziel für das Gesetz unter
anderem angebracht, dass man in Krisenzeiten besonderen Einfluss auf die
Anbieter sehr großer Online-Plattformen nehmen will. Zusätzlich zu den
grundsätzlich angeordneten Maßnahmen, die von den Anbietern ergriffen
werden müssen, sollen weitere Mittel hinzukommen, wenn es als
erforderlich angesehen wird. Krisensituationen, so definiert es das
Gesetz, können dabei zum Beispiel bewaffnete Konflikte, Terroranschläge,
Naturkatastrophen oder Pandemien sein.

Als spezifisches Mittel wird beispielsweise konkret erwogen, dass
Anbieter von Online-Plattformen oder Suchmaschinen ihre Verfahren zur
Inhaltsmoderation anpassen oder verschärfen müssen, sogar in das Design
ihrer Online-Schnittstellen oder die Allgemeinen Geschäftsbedingungen
kann eingegriffen werden. Außerdem kann eine „weitere Intensivierung der
Zusammenarbeit mit vertrauenswürdigen Hinweisgebern, die Durchführung
von Sensibilisierungsmaßnahmen und die Förderung vertrauenswürdiger
Informationen“ angeordnet werden.

Über die Vertrauenswürdigkeit der Informationen und Hinweisgeber soll
die Kommission auf Empfehlung des Europäischen Gremiums für digitale
Dienste entscheiden, genauso über die Auswahl der angeordneten
Maßnahmen. Es ist weiterhin sicherzustellen, dass dies in kürzester Zeit
umsetzbar ist – unter der Berücksichtigung der Rechte und berechtigten
Interessen aller betroffenen Parteien, versteht sich. Im Gesetz wird
dies unter dem Punkt „Krisenreaktionsmechanismus“ verbindlich verankert.

### Eine Gefahr für die Meinungsfreiheit und die verfassungsmäßige Ordnung

Die EU beweist mit den Digital Service Act hemmungslos, was für ein
breites Spektrum an staatlichen Eingriffen, Kontrollen und
Zwangsmaßnahmen sie sich anmaßt. Besonders kritisch zu sehen, ist dabei
der doppelte Begriff der systematischen Risiken. Dass es Inhalte gibt,
die gewissermaßen strafbar sind, ohne rechtswidrig zu sein, sollte zu
bedenken geben. Die Löschung von Meinungsäußerungen im digitalen Raum
bedeutet einen harten Eingriff in die Meinungsfreiheit. Die Sperrung des
ganzen Accounts erst recht. Strafrechtliche Konsequenzen hin oder her,
für den Betroffenen entsprichen diese Einschränkungen einer Bestrafung –
für die es eine eindeutige Rechtsgrundlage geben sollte.

Man macht Plattformen wie Twitter und Google zu Hilfspolizisten und
verpflichtet sie zu feuern. Sie müssen „systematische Risiken“
überwachen und bekämpfen. Die EU hat sich genug Mittel zurechtgelegt, um
die Plattformen unter einen dauernden unaufhörlichen Druck zu setzen –
der ohne Zweifel zur Folge haben wird, dass Inhalte zensiert werden, die
eigentlich völlig legal waren. Denn das Gesetz legt ja schwarz auf weiß
fest, dass die zu zensierenden Inhalte und die strafbaren Inhalte nicht
deckungsgleich sind – dass es Inhalte geben muss, die legal aber
trotzdem verboten sind.

Geldstrafen, zahlreiche Kontrollinstanzen – der Druck ist hoch. Die
jährlich angesetzten Untersuchungen lesen sich wie Razzien, alles muss
zur Verfügung gestellt werden, jeder muss kooperieren, die Rücksicht auf
die Rechte der Betroffenen ist ausdrücklich begrenzt – sobald es zu
Unannehmlichkeiten kommt, hat die staatliche Kontrolle Vorrang. Man
behandelt nicht nur Nutzer, die von ihrer Meinungsfreiheit Gebrauch
machen, wie potentielle Gefährder. Man behandelt auch die
Plattform-Anbieter wie Kriminelle auf Bewährung.

Aus dem Gesetzestext muss man beinahe unweigerlich schließen: Es ist
verboten, was nicht erlaubt ist. Es gibt eine Wahrheit und dann gibt es
noch „systematische Risiken“ – wer unter letzteres fällt, der betritt
einen rechtsfreien Raum, ohne Meinungsfreiheit, ohne Vorbehalt des
Gesetzes. Da ist einfach nur Funkstille. Das alles soll die
Meinungsfreiheit schützen. Doch wessen Meinungsfreiheit? Die jener
Nutzer, die sich selbst zensieren, bevor die Plattformanbieter es aus
Angst vor Milliardenbußgeldern tun? Man bekommt den Eindruck, dieses
Gesetz soll nur einen schützen: Die EU.

</blockquote>

------------------------------------------------------------------------

\[Export of Github issue for
[milahu/alchi](https://github.com/milahu/alchi).\]
